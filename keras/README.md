# Keras

Python으로 구현된 쉽고 간결한 딥러닝 라이브러리
다층퍼셉트론, 컨벌루션 신경망, 순환 신경망 등 구현 가능

## Keras의 주요 특징

### 모듈화

- Keras에서 제공하는 모듈은 독립적이고 설정 가능
- 가능한 최소한의 제약사항으로 서로 연결 가능

### 최소주의

- 각 모듈은 짧고 간결하다
- 모든 코드는 한번 훑어 보는 것으로도 이해 가능해야 한다
- 반복 속도와 혁신성에는 다소 떨어질 수 있다

### 쉬운 확장성

- 새로운 클래스나 함수로 모듈을 아주 쉽게 추가할 수 있다
- 고급 연구에 필요한 다양한 표현 가능

### Python 기반

- 별도의 모델 설정 파일이 필요없으며 파이썬 코드로 모델들이 정의된다.

## Keras 기본 개념

### 데이터 생성하기

- 원본 데이터를 불러오거나 시뮬레이션을 통해 데이터 생성
- 훈련셋, 검증셋, 시험셋 생성
- 모델의 학습 및 평가를 할 수 있도록 포맷 변환

### 모델 구성하기

- 시퀀스 모델을 생성한 뒤 필요한 레이어를 추가하여 구성
- 복잡한 모델이 필요할 때는 Keras 함수 API를 사용

### 모델 학습과정 설정하기

- 학습하기 전에 학습에 대한 설정을 수행
- 손실 함수 및 최적화 방법을 정의
- Keras에서는 compile() 함수를 사용

### 모델 학습시키기

- 훈련셋을 이용하여 구성한 모델로 학습
- 케라스에는 fit() 함수 사용

### 학습 과정 살펴보기

- 모델 학습 시 훈련셋, 검증셋의 손실 및 정확도를 측정
- 반복횟수에 따른 손실 및 정확도 추이를 보면서 학습 상황 판단

### 모델 평가하기

- 준비된 시험셋으로 학습한 모델을 평가
- Keras에서는 evaluate() 함수를 사용

### 모델 사용하기

- 임의의 입력으로 모델의 출력을 얻는다
- Keras에서는 predict() 함수를 사용

## 주요 함수들

### 1. Preprocessing(전처리)

#### Tokenizer(): 토큰화와 정수 인코딩(단어에 대한 인덱싱)을 위해 사용

#### pad_sequence(): padding 함수, 길이가 긴 샘플은 일부 자르고, 짧은 샘플은 0으로 값을 채움

- 첫번째 인자: 패딩을 진행할 데이터
- 두번째 인자: 모든 데이터에 대해서 정규화 할 길이
- 세번째 인자: 'pre'를 선택하면 앞에 0을 채우고, 'post'를 선택하면 뒤에 0을 채움

### 2. Word Embedding(워드 임베딩)

: Text내의 단어들을 dense vector(밀집 벡터)로 만드는 것, 상대적으로 저차원이며 실수값을 가진다.

#### Embedding(): 단어를 밀집 벡터를 만들 때 사용, 임베딩 층을 만드는 역할

- 2D 텐서를 입력받아 3D 텐서를 리턴
- (number of samples, input_length) -> (number of samples, input_length, embedding word dimensionality)
- 첫번째 인자: 단어 집합의 크기, 총 단어의 개수
- 두번째 인자: 임베딩 벡터의 출력 차원, 결과로서 나오는 임베딩 벡터의 크기
- input_length: 입력 시퀸스의 길이

### 3. Modeling(모델링)

#### Sequential(): 입력층, 은닉층, 출력층을 구성하기 위해 사용

- Sequential()을 model로 선언한 뒤에 model.add()를 이용해 층을 단계적으로 추가
- Embedding()을 통해 생성하는 임베딩 층(embedding layer) 또한 인공 신경망의 층의 하나이므로 model.add()로 추가

#### Dense(): 전결합층(fully-conntected latey)을 추가, 역시 model.add()를 통해 추가 가능

- 첫번째 인자: 출력 뉴런의 수
- input_dim: 입력 뉴런의 수(입력의 차원)
- activation: 활성화 함수
- 1. linear : 디폴트 값으로 별도 활성화 함수 없이 입력 뉴런과 가중치의 계산 결과 그대로 출력 Ex) 선형 회귀
- 2. sigmoid : 이진 분류 문제에서 출력층에 주로 사용되는 활성화 함수
- 3. softmax : 셋 이상을 분류하는 다중 클래스 분류 문제에서 출력층에 주로 사용되는 활성화 함수
- 4. relu : 은닉층에 주로 사용되는 활성화 함수

#### summary(): 모델의 정보를 요약해서 보여줌

### 4. Compile(컴파일)과 Training(훈련)

#### compile(): 모델을 기계가 이해할 수 있도록 컴파일, 오차 함수와 최적화 방법, 메트릭 함수를 선택할 수 있음

- optimizer : 훈련 과정을 설정하는 옵티마이저를 설정
- loss: 'adam'이나 'sgd'와 같이 문자열로 지정 가능
  loss : 훈련 과정에서 사용할 손실 함수(loss function)를 설정
- metrics : 훈련을 모니터링하기 위한 지표를 선택

#### fit(): 모델을 학습

- 첫번째 인자: 훈련 데이터에 대항
- 두번째 인자: 지도 학습에서 레이블 데이터에 해당
- epochs: 총 훈련 횟수(반복횟수)
- batch_size: 기본값은 32, 미니 배치 경사 하강법을 사용하고 싶지 않을 경우에는 batch_size = None을 기재
- validation_data(x_val, y_val): 검증 데이터를 사용, 검증 데이터의 loss가 낮아지다가 높아지기 시작하면 이는 과적합의 신호
- validation_split: validation_data 대신 사용 가능, 검증 데이터를 사용하는 것은 동일하지만 train 데이터에서 일정 비율을 분리하여 이를 검증데이터로 사용
- verbose: 학습 중 출력되는 문구를 설정
- 0. 아무 것도 출력하지 않음
- 1. 훈련의 진행도를 보여주는 진행 막대를 보여줌
- 2. 미니 배치마다 손실 정보를 출력

### 5. Evaluation(평가)와 Prediction(예측)

#### evaluate(): 테스트 데이터를 통해 학습한 모델에 대한 정확도를 평가

- 첫번째 인자: 테스트 데이터에 해당
- 두번째 인자: 지도 학습에서 레이블 테스트 데이터에 해당
- batch_size: 배치 크기

#### predict(): 임의의 입력에 대한 모델의 출력값 확인

- 첫번째 인자: 예측하고자 하는 데이터
- batch_size: 배치 크기

### 6. Save & Load

#### save(): 모델을 hdf5 파일에 저장

#### load_model() 저장해둔 모델 불러오기
